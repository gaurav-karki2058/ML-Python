{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gk/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU\n",
    "\n",
    "Rectified Linear Unit (ReLU) is the goto activation function for hidden layers in present days replacing sigmoid function which was generally used. It replaces negative activations with zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z_values):\n",
    "    return np.maximum(0,Z_values)\n",
    "# def leaky_relu(x, alpha=0.01):\n",
    "#     return np.where(Z_values > 0, Z_values, 0.01 * Z_values)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(in_dim,out_dim):\n",
    "    return np.random.randn(in_dim,out_dim) * np.sqrt(2 / in_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Derivative\n",
    "\n",
    "Modifies activation values to 0 or 1. Value is modified to 1 if activation value is greater than 0 else modified to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_derivative(x):\n",
    "    return (x > 0).astype(int)\n",
    "# def ReLU_derivative(x, epsilon=1e-8):\n",
    "#     return (x > epsilon).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, Layers, Weights=None, Biases=None):\n",
    "    # Initialize weights and biases if unspecified\n",
    "    if Weights is None:\n",
    "        Weights=[]\n",
    "        \n",
    "        Weights.append(initialize_weights(X.shape[1], Layers[0]))\n",
    "       \n",
    "\n",
    "        for i in range(1, len(Layers)):\n",
    "            Weights.append( initialize_weights(Weights[i-1].shape[1], Layers[i]))\n",
    "#         Weights = []\n",
    "#         Weights.append(np.random.randn(X.shape[1], Layers[0]) * np.sqrt(2 / X.shape[1]))\n",
    "#         for i in range(1, len(Layers)):\n",
    "#             Weights.append(np.random.randn(Layers[i-1], Layers[i]) * np.sqrt(2 / Layers[i-1]))\n",
    "\n",
    "\n",
    "    if Biases is None:\n",
    "        Biases=[]\n",
    "        Biases = [2*np.random.rand(n_units)-1 for n_units in Layers]\n",
    "    \n",
    "    Z_values = []\n",
    "    Activations = []\n",
    "    \n",
    "    print(\"Starting forward propagation...\")\n",
    "    \n",
    "    # First layer\n",
    "    dot_product = np.dot(X, Weights[0]) \n",
    "    L1_value = dot_product + Biases[0][np.newaxis, :]\n",
    "    Z_values.append(L1_value)\n",
    "    Activations.append(ReLU(L1_value))\n",
    "#     print(f\"Layer 1 Activation Shape: {Activations[-1].shape} Weights Shape : {Weights[0].shape}\")\n",
    "    \n",
    "    # Remaining layers\n",
    "    for i in range(len(Layers) - 1):  \n",
    "        dot_product = np.dot(Activations[i], Weights[i+1])\n",
    "        Z_value = dot_product + Biases[i+1]\n",
    "        Z_values.append(Z_value)\n",
    "        Activations.append(ReLU(Z_value))\n",
    "#         print(f\"Layer {i + 2} Activation Shape: {Activations[-1].shape}\")\n",
    "    y_cap=[Activations[-1]]\n",
    "    \n",
    "    return Activations, Weights, Biases, y_cap, Z_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting forward propagation...\n",
      "Layer 1 Activation: [[1.96930767 2.68755358 1.55731584 1.20300941]\n",
      " [1.87297958 2.52746701 1.44064505 1.12315345]\n",
      " [1.47586787 1.84894602 0.82065061 0.60346584]\n",
      " [1.50248313 2.02966925 0.8874962  0.80174443]\n",
      " [1.63974075 2.13773793 1.05255493 0.79682393]\n",
      " [1.74505486 2.35058206 1.26688148 1.02864602]\n",
      " [1.31309254 1.67008895 0.60006417 0.52898951]\n",
      " [1.55441201 2.00406193 1.04833789 0.85692558]\n",
      " [1.48819135 1.90947733 0.93744734 0.7790926 ]\n",
      " [1.45282186 1.91491994 0.89533551 0.81339709]] \n",
      "\n",
      " Weights: [[0.49432972 0.90006799 0.61295213 0.50415429]\n",
      " [0.18830369 0.19872718 0.47001847 0.34451054]\n",
      " [0.51691989 0.78766465 0.58559154 0.30859341]]\n",
      "\n",
      " Biases: [0.88645318 0.98736778 0.03100566 0.13613326]\n",
      "\n",
      "\n",
      "Layer 2 Activation: [[5.60986478 5.40797084]\n",
      " [5.28455908 5.11706302]\n",
      " [3.6193162  3.75176039]\n",
      " [3.9720864  4.02547934]\n",
      " [4.26722982 4.30039224]\n",
      " [4.86146662 4.75231508]\n",
      " [3.14591846 3.34145437]\n",
      " [4.20317214 4.15521155]\n",
      " [3.93501728 3.94113058]\n",
      " [3.90586057 3.90910169]] \n",
      "\n",
      " Weights: [[0.70118998 0.38351137]\n",
      " [0.4366778  0.92325079]\n",
      " [0.94795866 0.74915455]\n",
      " [0.96744269 0.23492783]]\n",
      "\n",
      " Biases: [0.41529728 0.72214234]\n",
      "\n",
      "\n",
      "Layer 3 Activation: [[3.08300435]\n",
      " [2.94725656]\n",
      " [2.25432129]\n",
      " [2.40086952]\n",
      " [2.52420442]\n",
      " [2.77091825]\n",
      " [2.05698188]\n",
      " [2.49608345]\n",
      " [2.38459108]\n",
      " [2.37233001]] \n",
      "\n",
      " Weights: [[0.40314963]\n",
      " [0.01581571]]\n",
      "\n",
      " Biases: [0.73585855]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activation_values,W,B,_,_=forward_propagation(np.random.rand(10,3),Layers=[4,2,1])\n",
    "for i in range(len(activation_values)):\n",
    "    print(f\"Layer {i+1} Activation: {activation_values[i]} \\n\\n Weights: {W[i]}\\n\\n Biases: {B[i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MSE as cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(Y, calculated_value):\n",
    "    cost = np.mean((np.array(Y) - calculated_value) ** 2) / 2\n",
    "    print(f\"Cost: {cost}\")\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Gradients \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(Y, Weights, Biases, Activations):\n",
    "    print(\"Calculating gradients...\")\n",
    "    weight_gradient = []\n",
    "    bias_gradient = []\n",
    "    \n",
    "    # Output layer\n",
    "    activation_gradient = (Activations[-1] - np.array(Y).reshape(-1, 1))/len(Y)\n",
    "    Z_gradient = activation_gradient * ReLU_derivative(Activations[-1])\n",
    "    W_gradient = np.dot(Z_gradient.T, Activations[-2])\n",
    "    weight_gradient.insert(0, W_gradient.T)\n",
    "    bias_gradient.insert(0, np.sum(Z_gradient, axis=0))\n",
    "#     print(f\"Output Layer Gradients - W: {W_gradient.shape}, B: {bias_gradient[-1].shape}\")\n",
    "    \n",
    "    # Hidden layers\n",
    "    for i in range(1, len(Weights)):\n",
    "        activation_gradient = np.dot(Z_gradient, Weights[-i].T)\n",
    "        Z_gradient = activation_gradient * ReLU_derivative(Activations[-i-1])\n",
    "        W_gradient = np.dot(Z_gradient.T, Activations[-i-2])\n",
    "        weight_gradient.insert(0, W_gradient.T)\n",
    "        bias_gradient.insert(0, np.sum(Z_gradient, axis=0))\n",
    "#         print(f\"Layer {len(Weights) - i} Gradients - W: {W_gradient.shape}, B: {bias_gradient[-1].shape}\")\n",
    "    \n",
    "    for i in range(len(weight_gradient)):\n",
    "        print(f\"Layer: {i+1} \\n\")\n",
    "        print(f\" weight : {Weights[i]}\\n weight_grad :{weight_gradient[i]} \\n\\n\")\n",
    "        print(f\" bias : {Biases[i]} \\n bias_grad :{bias_gradient[i]}\\n\\n\\n\")\n",
    "\n",
    "    return weight_gradient, bias_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, W, b, Activations, learning_rate):\n",
    "    print(\"Performing backward propagation...\")\n",
    "    new_activation = Activations.copy()\n",
    "    new_activation.insert(0, X)\n",
    "    \n",
    "    weight_gradient, bias_gradient = calculate_gradients(Y, W, b, new_activation)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    new_weights = []\n",
    "    new_biases = []\n",
    "    for i in range(len(W)):\n",
    "        new_weights.append(W[i] - learning_rate * weight_gradient[i])\n",
    "        new_biases.append(b[i] - learning_rate * bias_gradient[i])\n",
    "#         print(f\"Updated Layer {i + 1} Weights Shape: {new_weights[-1].shape}, Biases Shape: {new_biases[-1].shape}\")\n",
    "    \n",
    "    return new_weights, new_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(X, y, Layers, iterations, learning_rate, error_margin):\n",
    "    print(\"Training MLP...\")\n",
    "    iteration_count = 0\n",
    "    cost = 100\n",
    "    cost_history = []\n",
    " \n",
    "    \n",
    "    while iteration_count < iterations:\n",
    "#     while iteration_count < 20: #Using fixed custom iterations for testing\n",
    "        print(f\"\\nIteration {iteration_count + 1}\")\n",
    "        activation, weight, bias, _,_ = forward_propagation(X, Layers)\n",
    "        cost = calculate_cost(y, activation[-1])\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        W, B = backward_propagation(X, y, weight, bias, activation, learning_rate)\n",
    "        \n",
    "        if cost <= error_margin:\n",
    "            print(\"Error margin reached, stopping training.\")\n",
    "            break\n",
    "        \n",
    "        iteration_count += 1\n",
    "    \n",
    "    return W, B, Layers, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP...\n",
      "\n",
      "Iteration 1\n",
      "Starting forward propagation...\n",
      "Cost: 2750.3863928416495\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.88294928 -0.07891642  0.62114588]\n",
      " [-0.76084723  1.693846    1.35593359]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [ 0.96115945  0.49130908 -0.14709223] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.28635523]\n",
      " [-1.13519258]\n",
      " [-0.04848915]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.64194599] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "Starting forward propagation...\n",
      "Cost: 2736.5055546128096\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.80528256 -0.56969308  0.03890093]\n",
      " [-0.84057024  1.1519571   0.46314712]]\n",
      " weight_grad :[[  0.           4.16480333  -5.81792175]\n",
      " [  0.         -16.08888247  25.48003512]] \n",
      "\n",
      "\n",
      " bias : [-0.49275216  0.96408162  0.14442531] \n",
      " bias_grad :[  0.         -15.50305113  23.62444366]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.53847284]\n",
      " [ 0.52448885]\n",
      " [-0.82137653]]\n",
      " weight_grad :[[  0.46744256]\n",
      " [-68.3571603 ]\n",
      " [-18.2449882 ]] \n",
      "\n",
      "\n",
      " bias : [-0.29710462] \n",
      " bias_grad :[-29.55839971]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "Starting forward propagation...\n",
      "Cost: 2744.1648290500825\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.31370079 -0.53759782 -0.18356835]\n",
      " [ 1.47053764  1.93018919 -1.69127768]]\n",
      " weight_grad :[[ 1.3167728  -2.9362859   0.55560243]\n",
      " [-1.15353751  0.72810327 -2.71607901]] \n",
      "\n",
      "\n",
      " bias : [ 0.45639103 -0.72409348 -0.8046016 ] \n",
      " bias_grad :[3.82853993 2.95425127 2.60149824]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.76064008]\n",
      " [-1.44504474]\n",
      " [-0.49018592]]\n",
      " weight_grad :[[-2.26858335]\n",
      " [-0.37375093]\n",
      " [-4.84672449]] \n",
      "\n",
      "\n",
      " bias : [0.79736986] \n",
      " bias_grad :[-12.91037644]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 4\n",
      "Starting forward propagation...\n",
      "Cost: 2711.997768621748\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.01487498  0.56169563  0.14058483]\n",
      " [-1.36728902  0.02430855  0.23956765]]\n",
      " weight_grad :[[6.20332342 1.63015241 0.        ]\n",
      " [0.16601314 1.34202923 0.        ]] \n",
      "\n",
      "\n",
      " bias : [ 0.83410385  0.34918043 -0.6223861 ] \n",
      " bias_grad :[10.00446452  2.06762896  0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.39953823]\n",
      " [-0.04790589]\n",
      " [ 0.23327576]]\n",
      " weight_grad :[[-19.83065733]\n",
      " [-34.84340629]\n",
      " [  0.21689962]] \n",
      "\n",
      "\n",
      " bias : [0.85241042] \n",
      " bias_grad :[-54.21585403]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 5\n",
      "Starting forward propagation...\n",
      "Cost: 2744.9487985435767\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.8519191  -2.42080874  1.05048738]\n",
      " [-0.53434118 -0.13789627  1.10421155]]\n",
      " weight_grad :[[ 3.08076438 -0.24169243 -2.54718334]\n",
      " [ 5.23969144  2.05237595 -9.19834716]] \n",
      "\n",
      "\n",
      " bias : [ 0.33604389  0.16291399 -0.03375625] \n",
      " bias_grad :[ 4.06270755  1.46012509 -6.58724135]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.70918859]\n",
      " [-0.38835649]\n",
      " [ 0.61052234]]\n",
      " weight_grad :[[ -5.99487715]\n",
      " [ -1.27224751]\n",
      " [-20.65500908]] \n",
      "\n",
      "\n",
      " bias : [-0.32595189] \n",
      " bias_grad :[-10.78951722]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 6\n",
      "Starting forward propagation...\n",
      "Cost: 2694.4708542233075\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.17638542  0.8749477  -0.85699734]\n",
      " [-0.09738458  1.19548839  0.80336939]]\n",
      " weight_grad :[[  3.40223636  -5.05114409  16.37487064]\n",
      " [ -2.93463888  13.43424968 -27.94072533]] \n",
      "\n",
      "\n",
      " bias : [-0.34643625  0.79053054  0.53403415] \n",
      " bias_grad :[ -3.98418924  16.78644203 -32.37949561]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.25702544]\n",
      " [-0.67472698]\n",
      " [ 1.30383234]]\n",
      " weight_grad :[[ -8.97285732]\n",
      " [-36.88979355]\n",
      " [-41.17498594]] \n",
      "\n",
      "\n",
      " bias : [0.70077345] \n",
      " bias_grad :[-31.34392409]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 7\n",
      "Starting forward propagation...\n",
      "Cost: 2745.6513337583183\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.99180815  0.17477819  0.44336523]\n",
      " [-1.54007822  0.80015681 -0.16281326]]\n",
      " weight_grad :[[ 0.96101651 -1.02828708 -0.02956119]\n",
      " [-2.01801269 -0.5824676   0.44191901]] \n",
      "\n",
      "\n",
      " bias : [-0.19214111  0.58827025  0.48176287] \n",
      " bias_grad :[ 3.62248445 10.41261597 -1.59847748]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.4920722 ]\n",
      " [-0.92035822]\n",
      " [ 0.12965552]]\n",
      " weight_grad :[[-6.77828258]\n",
      " [-5.94564674]\n",
      " [-6.59437301]] \n",
      "\n",
      "\n",
      " bias : [0.8050788] \n",
      " bias_grad :[-13.96812646]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 8\n",
      "Starting forward propagation...\n",
      "Cost: 2630.6996004543416\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.51229794 -0.31565431  1.21064415]\n",
      " [ 1.24143131  0.7067602  -0.68834023]]\n",
      " weight_grad :[[-46.77059059   5.08914502  11.60956738]\n",
      " [-36.53051167  11.187021     2.04238044]] \n",
      "\n",
      "\n",
      " bias : [-0.34504507  0.70451572  0.3202136 ] \n",
      " bias_grad :[-51.55138465  14.81040988  10.73003654]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 1.29708604]\n",
      " [-0.29410836]\n",
      " [-0.28233497]]\n",
      " weight_grad :[[-75.58883238]\n",
      " [-56.86779422]\n",
      " [-56.72598351]] \n",
      "\n",
      "\n",
      " bias : [0.85635349] \n",
      " bias_grad :[-59.72576836]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 9\n",
      "Starting forward propagation...\n",
      "Cost: 2708.1816841173927\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.15508662 -0.1106489  -1.19359608]\n",
      " [ 0.54820627 -0.14065881  0.6682176 ]]\n",
      " weight_grad :[[  5.73595124  -2.3852019    6.51396872]\n",
      " [ 15.40318972   0.82659941 -19.07495673]] \n",
      "\n",
      "\n",
      " bias : [0.10883383 0.14268737 0.50443697] \n",
      " bias_grad :[ 19.43370097 -17.74859406 -21.0106651 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.49970165]\n",
      " [ 0.52991456]\n",
      " [ 0.69951587]]\n",
      " weight_grad :[[-22.87093206]\n",
      " [ -4.48427761]\n",
      " [-44.22846292]] \n",
      "\n",
      "\n",
      " bias : [0.34381331] \n",
      " bias_grad :[-52.51597]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 10\n",
      "Starting forward propagation...\n",
      "Cost: 2728.916798761018\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.7405985  -0.93520401  1.4743613 ]\n",
      " [-0.36789675 -0.36163463 -1.12569866]]\n",
      " weight_grad :[[-2.70067896  0.         -3.20003219]\n",
      " [ 2.51202076  0.         -0.39084726]] \n",
      "\n",
      "\n",
      " bias : [ 0.01327825 -0.4578005   0.19919791] \n",
      " bias_grad :[ 5.68155256  0.         -2.66498889]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.99635263]\n",
      " [-0.04289152]\n",
      " [ 0.0752773 ]]\n",
      " weight_grad :[[ -0.77018947]\n",
      " [  0.69116789]\n",
      " [-63.62458304]] \n",
      "\n",
      "\n",
      " bias : [0.30392308] \n",
      " bias_grad :[-51.7634202]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 11\n",
      "Starting forward propagation...\n",
      "Cost: 2589.8669927999963\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.14025565 -0.46750123 -0.53337051]\n",
      " [ 0.95001223  0.00568609  0.01806986]]\n",
      " weight_grad :[[-70.42329571   0.           0.64102338]\n",
      " [-59.7486265    0.          -0.83950799]] \n",
      "\n",
      "\n",
      " bias : [ 0.64875922 -0.94098253 -0.65880687] \n",
      " bias_grad :[-98.97423759   0.          -0.51835703]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[2.01860885]\n",
      " [0.29122801]\n",
      " [0.58525544]]\n",
      " weight_grad :[[-99.70873562]\n",
      " [  0.62278668]\n",
      " [  0.47740058]] \n",
      "\n",
      "\n",
      " bias : [-0.91294743] \n",
      " bias_grad :[-49.03091429]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 12\n",
      "Starting forward propagation...\n",
      "Cost: 2748.9928382161825\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.38223192  0.27446607 -0.68424451]\n",
      " [ 1.40028781 -1.14078413  0.20968866]]\n",
      " weight_grad :[[4.90581737 1.48531355 0.        ]\n",
      " [5.23229424 3.12137857 0.        ]] \n",
      "\n",
      "\n",
      " bias : [-0.96775566  0.98320309 -0.27589602] \n",
      " bias_grad :[4.51435417 3.34984005 0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.95625356]\n",
      " [-1.8650132 ]\n",
      " [-0.53808233]]\n",
      " weight_grad :[[-1.13230016]\n",
      " [-0.07261666]\n",
      " [ 0.03665469]] \n",
      "\n",
      "\n",
      " bias : [0.39557648] \n",
      " bias_grad :[-4.72087565]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 13\n",
      "Starting forward propagation...\n",
      "Cost: 2732.1156830675086\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.49619414 -0.3675842  -0.76886888]\n",
      " [-1.0396107  -0.57939694  0.1466785 ]]\n",
      " weight_grad :[[0.         6.55223234 0.07864863]\n",
      " [0.         0.66191612 6.67436545]] \n",
      "\n",
      "\n",
      " bias : [-0.54644554  0.80991313  0.18562156] \n",
      " bias_grad :[0.         7.78598731 5.90819331]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.46765753]\n",
      " [-0.34697323]\n",
      " [-0.71691834]]\n",
      " weight_grad :[[  0.6514624 ]\n",
      " [-10.07815147]\n",
      " [ -2.58139492]] \n",
      "\n",
      "\n",
      " bias : [0.5351814] \n",
      " bias_grad :[-40.52460863]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 14\n",
      "Starting forward propagation...\n",
      "Cost: 2711.9398914744484\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.66131495 -0.82088228 -1.55345133]\n",
      " [ 1.14339538  0.97599549 -0.51613087]]\n",
      " weight_grad :[[ -0.55836695   8.48671535  14.08467673]\n",
      " [  1.23028833 -13.06497793 -14.62414321]] \n",
      "\n",
      "\n",
      " bias : [0.91215713 0.60025731 0.75986881] \n",
      " bias_grad :[  1.02917097 -13.72401904 -21.22461366]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.05826214]\n",
      " [ 0.63444061]\n",
      " [ 1.0151823 ]]\n",
      " weight_grad :[[-24.29229003]\n",
      " [-44.05355283]\n",
      " [-29.99471629]] \n",
      "\n",
      "\n",
      " bias : [-0.90688318] \n",
      " bias_grad :[-23.27338587]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 15\n",
      "Starting forward propagation...\n",
      "Cost: 2749.222694819594\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.41294819 -0.75418898  0.0365693 ]\n",
      " [-0.41711635 -0.16951576 -0.40933164]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [-0.7227561   0.10318976 -0.96359395] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.72030125]\n",
      " [-1.49229601]\n",
      " [ 0.63746383]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.57543226] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 16\n",
      "Starting forward propagation...\n",
      "Cost: 2751.815136416954\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.44033229  0.12526346  0.64290163]\n",
      " [-1.4343195   1.43027631  2.24732548]]\n",
      " weight_grad :[[ 0.          1.6726484  -2.0259265 ]\n",
      " [ 0.         -0.77157291  1.07354496]] \n",
      "\n",
      "\n",
      " bias : [ 0.97463106 -0.15234684 -0.23426579] \n",
      " bias_grad :[ 0.         -1.75969536  2.20153755]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-3.13750403]\n",
      " [ 1.06177872]\n",
      " [-1.67445144]]\n",
      " weight_grad :[[ 0.03033993]\n",
      " [-0.58005499]\n",
      " [-0.3269801 ]] \n",
      "\n",
      "\n",
      " bias : [0.14804984] \n",
      " bias_grad :[-3.99307599]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 17\n",
      "Starting forward propagation...\n",
      "Cost: 2750.2045736017726\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.190281    1.72751301  0.91675143]\n",
      " [-0.85601202  1.53987352 -0.58848658]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [ 0.97397408  0.47819198 -0.65912592] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.58218939]\n",
      " [-0.3797686 ]\n",
      " [ 0.41727637]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.88094975] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 18\n",
      "Starting forward propagation...\n",
      "Cost: 2733.8877223368486\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.29597095 -0.94317571  0.47024465]\n",
      " [ 0.73225631 -0.51793129  0.00629965]]\n",
      " weight_grad :[[  2.10517546  -8.69527011   0.        ]\n",
      " [-43.02989388  18.85215904   0.        ]] \n",
      "\n",
      "\n",
      " bias : [ 0.24984848  0.62484381 -0.58354221] \n",
      " bias_grad :[-30.61015454  13.5567515    0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 1.57863585]\n",
      " [-1.23843472]\n",
      " [-1.7709682 ]]\n",
      " weight_grad :[[-25.19889726]\n",
      " [ -5.51470697]\n",
      " [  0.1177041 ]] \n",
      "\n",
      "\n",
      " bias : [-0.92481749] \n",
      " bias_grad :[-19.39025686]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 19\n",
      "Starting forward propagation...\n",
      "Cost: 2739.9244106129972\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.48248675 -1.07243657 -0.52644442]\n",
      " [ 0.68518143 -0.61800442  0.14992766]]\n",
      " weight_grad :[[-0.69418583 -0.93596325  0.        ]\n",
      " [-8.71783164  3.73479175  0.        ]] \n",
      "\n",
      "\n",
      " bias : [-0.40927841  0.42920166 -0.82428585] \n",
      " bias_grad :[-5.79115374  3.53644456  0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.45295237]\n",
      " [-1.08781334]\n",
      " [ 0.04878575]]\n",
      " weight_grad :[[-6.95520891]\n",
      " [ 0.20871777]\n",
      " [ 0.51726641]] \n",
      "\n",
      "\n",
      " bias : [0.13220768] \n",
      " bias_grad :[-42.09445957]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 20\n",
      "Starting forward propagation...\n",
      "Cost: 2681.628892092658\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 2.75617262 -0.04152854 -0.49146693]\n",
      " [ 1.2636772  -2.89056588 -1.50640206]]\n",
      " weight_grad :[[-24.46440506   7.59499348   0.        ]\n",
      " [-18.9310093   -1.28886135   0.        ]] \n",
      "\n",
      "\n",
      " bias : [-0.14310706 -0.12356113 -0.76422215] \n",
      " bias_grad :[-23.11017864   5.84512044   0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.7635721 ]\n",
      " [-2.26149777]\n",
      " [-0.25529929]]\n",
      " weight_grad :[[-115.3048666 ]\n",
      " [  -0.40931158]\n",
      " [   0.76223932]] \n",
      "\n",
      "\n",
      " bias : [-0.66515177] \n",
      " bias_grad :[-30.26587638]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 21\n",
      "Starting forward propagation...\n",
      "Cost: 2745.5466484921194\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.64699665 -0.33455724  1.73599514]\n",
      " [-0.43052546 -0.22036277  1.52568225]]\n",
      " weight_grad :[[-0.8302597  -0.09314987  0.47458015]\n",
      " [ 1.59679866 -0.09498576 -0.19496013]] \n",
      "\n",
      "\n",
      " bias : [ 0.14142421 -0.54281804 -0.57551093] \n",
      " bias_grad :[-1.69390334  0.07943308  0.73333263]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.17296116]\n",
      " [-0.20110895]\n",
      " [-0.61111676]]\n",
      " weight_grad :[[-8.37157367]\n",
      " [ 0.05426023]\n",
      " [ 0.09593477]] \n",
      "\n",
      "\n",
      " bias : [0.09151733] \n",
      " bias_grad :[-22.77790553]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 22\n",
      "Starting forward propagation...\n",
      "Cost: 2674.6728573492414\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.13452138  0.71411461  1.18707916]\n",
      " [ 0.78464342 -0.15281936  0.20280411]]\n",
      " weight_grad :[[-21.79631616 -18.25670187  -8.60359439]\n",
      " [-55.90811299 -13.60802921  -4.88172633]] \n",
      "\n",
      "\n",
      " bias : [0.11029046 0.98521802 0.65244463] \n",
      " bias_grad :[-57.17092416 -27.95211093 -10.60503108]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[1.37530068]\n",
      " [0.51492722]\n",
      " [0.21482602]]\n",
      " weight_grad :[[-34.25831757]\n",
      " [-74.75764812]\n",
      " [-84.32932911]] \n",
      "\n",
      "\n",
      " bias : [-0.53387573] \n",
      " bias_grad :[-56.59697837]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 23\n",
      "Starting forward propagation...\n",
      "Cost: 2748.7900294841534\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.22282639 -0.7899346  -1.08193993]\n",
      " [ 0.07965851  0.24715654  1.34722239]]\n",
      " weight_grad :[[ 0.         -0.72773139  0.17655561]\n",
      " [ 0.          2.33841651 -3.27486565]] \n",
      "\n",
      "\n",
      " bias : [-0.80243336 -0.70028404 -0.71565102] \n",
      " bias_grad :[ 0.          1.45615263 -1.98602609]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.66016938]\n",
      " [-1.49360281]\n",
      " [ 0.46024399]]\n",
      " weight_grad :[[ 0.02426726]\n",
      " [-0.07861708]\n",
      " [-6.91305785]] \n",
      "\n",
      "\n",
      " bias : [-0.65086438] \n",
      " bias_grad :[-4.31515921]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 24\n",
      "Starting forward propagation...\n",
      "Cost: 2674.8722075726955\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.58964045  0.83703009  1.19940366]\n",
      " [ 0.54514044  0.36789217  1.01232755]]\n",
      " weight_grad :[[  7.77791003 -22.37360063  11.11293877]\n",
      " [-29.61291028 -16.13715642  10.32784092]] \n",
      "\n",
      "\n",
      " bias : [0.12134343 0.44623659 0.77883729] \n",
      " bias_grad :[-28.90049767 -32.04333573  18.40138019]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.98534536]\n",
      " [ 0.6034788 ]\n",
      " [-0.33362868]]\n",
      " weight_grad :[[ -24.40122391]\n",
      " [ -64.53876368]\n",
      " [-114.21176798]] \n",
      "\n",
      "\n",
      " bias : [0.79484847] \n",
      " bias_grad :[-60.6087493]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 25\n",
      "Starting forward propagation...\n",
      "Cost: 2712.952233878825\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.93738515 -0.38156271  0.6651687 ]\n",
      " [ 0.76722895 -1.45450245 -1.43757771]]\n",
      " weight_grad :[[ 0.15368098 -0.15811461  4.47271073]\n",
      " [-0.50058462 -1.85710414 -0.81065508]] \n",
      "\n",
      "\n",
      " bias : [-0.08510968 -0.20470642 -0.70566318] \n",
      " bias_grad :[-0.47107474  5.72434533  3.51986877]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.01718492]\n",
      " [-0.94211174]\n",
      " [-0.43503785]]\n",
      " weight_grad :[[-28.15162439]\n",
      " [ -0.92147661]\n",
      " [ -2.99985855]] \n",
      "\n",
      "\n",
      " bias : [0.71114119] \n",
      " bias_grad :[-52.58497574]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 26\n",
      "Starting forward propagation...\n",
      "Cost: 2716.9413166232016\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.46534507 -2.11101951  0.3513606 ]\n",
      " [ 0.50666209  0.43580936 -1.32586259]]\n",
      " weight_grad :[[  0.32612233   6.9814047   -6.98402538]\n",
      " [ -3.0540663  -12.72596639   1.55771777]] \n",
      "\n",
      "\n",
      " bias : [0.67251925 0.75756898 0.94560891] \n",
      " bias_grad :[ -2.55441108 -11.1871134    7.74218476]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.09372036]\n",
      " [ 0.57778744]\n",
      " [-2.22211561]]\n",
      " weight_grad :[[-36.45984451]\n",
      " [-49.69854985]\n",
      " [ -1.0617297 ]] \n",
      "\n",
      "\n",
      " bias : [0.09625368] \n",
      " bias_grad :[-27.2556694]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 27\n",
      "Starting forward propagation...\n",
      "Cost: 2749.1310131222813\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.16089849 -0.31729498 -1.29998023]\n",
      " [ 0.47396086 -0.11296289 -0.64903931]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [-0.62894703  0.44190107 -0.51961743] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.24604508]\n",
      " [-0.23820689]\n",
      " [ 0.06261481]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.57051942] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 28\n",
      "Starting forward propagation...\n",
      "Cost: 2677.5439573331496\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.2532102   1.66656506 -1.24412142]\n",
      " [ 1.12839969  0.47065548 -0.98984777]]\n",
      " weight_grad :[[ 25.61811902 -39.59452745   0.35650713]\n",
      " [ 26.97287964 -10.38921527   0.21601221]] \n",
      "\n",
      "\n",
      " bias : [-0.45772992 -0.71077154  0.06798869] \n",
      " bias_grad :[ 30.93059545 -31.21283264  -0.83396255]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.115355  ]\n",
      " [ 0.95534441]\n",
      " [ 0.0639405 ]]\n",
      " weight_grad :[[-20.20052544]\n",
      " [-50.71119794]\n",
      " [-10.55031947]] \n",
      "\n",
      "\n",
      " bias : [0.8610214] \n",
      " bias_grad :[-50.92609976]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 29\n",
      "Starting forward propagation...\n",
      "Cost: 2741.533592015224\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.91884297  1.1710483  -0.90176434]\n",
      " [-0.83717033 -0.13801899  0.42905928]]\n",
      " weight_grad :[[5.21293043 2.36714131 4.50752743]\n",
      " [1.69375295 0.86183692 6.1330045 ]] \n",
      "\n",
      "\n",
      " bias : [ 0.0441878  -0.02602808  0.53392213] \n",
      " bias_grad :[4.99574132 2.19784516 9.86614504]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.15472869]\n",
      " [-0.06930238]\n",
      " [-0.76693621]]\n",
      " weight_grad :[[-56.90111322]\n",
      " [-37.44929496]\n",
      " [ -4.88598496]] \n",
      "\n",
      "\n",
      " bias : [0.63654299] \n",
      " bias_grad :[-35.24454272]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 30\n",
      "Starting forward propagation...\n",
      "Cost: 2660.5842719649245\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.29612618  0.33191145 -2.48019954]\n",
      " [-0.37059396  0.05423184  1.0151267 ]]\n",
      " weight_grad :[[ -3.83332261 -35.07297776  14.33821579]\n",
      " [  5.83707509 -20.8322949  -22.89075399]] \n",
      "\n",
      "\n",
      " bias : [ 0.79306218  0.19559578 -0.44414597] \n",
      " bias_grad :[ 11.39836447 -45.16222389 -23.06487346]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.39543848]\n",
      " [ 0.88904186]\n",
      " [ 1.08485506]]\n",
      " weight_grad :[[-29.6252082 ]\n",
      " [-24.28987148]\n",
      " [-43.58688969]] \n",
      "\n",
      "\n",
      " bias : [0.49956744] \n",
      " bias_grad :[-59.27736385]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 31\n",
      "Starting forward propagation...\n",
      "Cost: 2734.9467072287134\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.50110407 -0.25961935  0.26238036]\n",
      " [-0.02775064 -1.25363608  0.30835581]]\n",
      " weight_grad :[[ 5.31818536 -1.58961554 -1.95753885]\n",
      " [-7.92304965  2.61723479 -1.48745868]] \n",
      "\n",
      "\n",
      " bias : [ 0.29456892 -0.16853556 -0.75613512] \n",
      " bias_grad :[-12.47445701  -3.14822966  -1.04695067]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.42792157]\n",
      " [0.21020564]\n",
      " [0.59004508]]\n",
      " weight_grad :[[-1.41829383e+01]\n",
      " [-1.04770562e+01]\n",
      " [-2.85455598e-03]] \n",
      "\n",
      "\n",
      " bias : [0.08795239] \n",
      " bias_grad :[-61.44529157]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 32\n",
      "Starting forward propagation...\n",
      "Cost: 2750.3752792660916\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.19270778  0.33826994 -0.85302818]\n",
      " [ 0.99357941 -2.32077503 -0.96588379]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [ 0.91995256  0.63620468 -0.41683301] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.89356259]\n",
      " [-0.65664474]\n",
      " [ 0.26870373]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.98073476] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 33\n",
      "Starting forward propagation...\n",
      "Cost: 2704.382558787761\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.37887539 -0.76783803  1.11319255]\n",
      " [ 0.87868955  1.01969174 -1.1574693 ]]\n",
      " weight_grad :[[ -8.52864713   0.26640993  10.80281796]\n",
      " [-17.77467057  -0.58915803   3.91531249]] \n",
      "\n",
      "\n",
      " bias : [-0.35917714 -0.65707168  0.34934914] \n",
      " bias_grad :[-17.12122254  -0.49444472  11.31805533]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.45036207]\n",
      " [ 0.02432074]\n",
      " [-0.46293654]]\n",
      " weight_grad :[[-28.12079242]\n",
      " [-19.49631774]\n",
      " [-24.38759701]] \n",
      "\n",
      "\n",
      " bias : [0.84908553] \n",
      " bias_grad :[-49.73439286]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 34\n",
      "Starting forward propagation...\n",
      "Cost: 2737.434111073201\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.62156832 -1.33227575 -2.51448102]\n",
      " [ 0.52752043  0.52397009  1.15688805]]\n",
      " weight_grad :[[ 4.53020362  8.32807408 -1.8205261 ]\n",
      " [ 1.54662311 -9.41477815  3.15919668]] \n",
      "\n",
      "\n",
      " bias : [ 0.52868385 -0.92834561  0.71888547] \n",
      " bias_grad :[ 4.97835262 -9.38568352  3.95744417]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.1184559 ]\n",
      " [ 0.62875798]\n",
      " [-0.16012972]]\n",
      " weight_grad :[[-91.027662  ]\n",
      " [-10.75618342]\n",
      " [-68.45654464]] \n",
      "\n",
      "\n",
      " bias : [0.47114514] \n",
      " bias_grad :[-55.67367885]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 35\n",
      "Starting forward propagation...\n",
      "Cost: 2660.384613165625\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.54248218 -0.39396633 -0.3944443 ]\n",
      " [ 1.94933058 -0.03532604 -2.19765733]]\n",
      " weight_grad :[[-13.23201721  -0.17507643  -3.80775701]\n",
      " [-40.75000892  25.43806476   5.0022888 ]] \n",
      "\n",
      "\n",
      " bias : [ 0.41403988  0.4684395  -0.48553561] \n",
      " bias_grad :[-41.8981462   40.35408624  -5.07238393]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 1.01885163]\n",
      " [-1.0707296 ]\n",
      " [ 0.43955256]]\n",
      " weight_grad :[[-87.69408739]\n",
      " [-16.84786358]\n",
      " [-14.81454173]] \n",
      "\n",
      "\n",
      " bias : [0.16671215] \n",
      " bias_grad :[-56.29649499]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 36\n",
      "Starting forward propagation...\n",
      "Cost: 2669.948073313313\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.16342518  0.42234673 -1.38011276]\n",
      " [-1.12444095  0.30031331  0.19997075]]\n",
      " weight_grad :[[ -4.71450121 -24.46139653   9.73267349]\n",
      " [  4.59867618 -23.08195752 -14.24553966]] \n",
      "\n",
      "\n",
      " bias : [-0.34335698  0.82679334  0.17526975] \n",
      " bias_grad :[ -5.47204362 -49.57189997 -16.83718569]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.36416726]\n",
      " [0.82155343]\n",
      " [0.70080253]]\n",
      " weight_grad :[[-10.57127001]\n",
      " [-70.9006854 ]\n",
      " [-26.92274112]] \n",
      "\n",
      "\n",
      " bias : [-0.04998493] \n",
      " bias_grad :[-60.55407573]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 37\n",
      "Starting forward propagation...\n",
      "Cost: 2686.010872221806\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.85206819  0.2703617  -0.03664176]\n",
      " [-2.62536353 -0.38699946  0.25014082]]\n",
      " weight_grad :[[-10.75203333 -49.78322128   0.        ]\n",
      " [ 11.53464768   0.78991642   0.        ]] \n",
      "\n",
      "\n",
      " bias : [ 0.9146564   0.60525263 -0.29087769] \n",
      " bias_grad :[-20.80523267 -52.50804965   0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[1.09173591]\n",
      " [1.48459954]\n",
      " [0.57551244]]\n",
      " weight_grad :[[-36.46101554]\n",
      " [-30.67885133]\n",
      " [  0.11649711]] \n",
      "\n",
      "\n",
      " bias : [-0.77911057] \n",
      " bias_grad :[-35.36849386]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 38\n",
      "Starting forward propagation...\n",
      "Cost: 2746.199461709941\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.37209733 -0.21741189  0.98493605]\n",
      " [-1.46278454 -0.2777611   1.01488095]]\n",
      " weight_grad :[[ 0.50976744  0.          0.09726802]\n",
      " [-0.33194915  0.          0.08372179]] \n",
      "\n",
      "\n",
      " bias : [-0.71936286 -0.86523196 -0.40445357] \n",
      " bias_grad :[0.39815877 0.         0.10979436]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.33051194]\n",
      " [-1.00574064]\n",
      " [-0.00275866]]\n",
      " weight_grad :[[  1.00092963]\n",
      " [  0.63087925]\n",
      " [-49.3543116 ]] \n",
      "\n",
      "\n",
      " bias : [0.0313409] \n",
      " bias_grad :[-54.36765879]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 39\n",
      "Starting forward propagation...\n",
      "Cost: 2749.9328900305936\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.37411779  1.1848577  -0.96363825]\n",
      " [-0.43601076 -0.79409504 -0.01934168]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [ 0.6166349  -0.23808654  0.11393734] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.05064628]\n",
      " [ 0.15944313]\n",
      " [-2.15130763]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.10343108] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 40\n",
      "Starting forward propagation...\n",
      "Cost: 2744.35241589047\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.54517188  0.34620978 -0.22798708]\n",
      " [ 0.00979411 -0.78962473  0.05468573]]\n",
      " weight_grad :[[ 1.08128524  1.79107274  0.        ]\n",
      " [-6.14069747  7.51155328  0.        ]] \n",
      "\n",
      "\n",
      " bias : [ 0.69678251  0.92137164 -0.6332832 ] \n",
      " bias_grad :[-4.44932047  6.8708761   0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.23981373]\n",
      " [-1.65614378]\n",
      " [ 0.94886269]]\n",
      " weight_grad :[[-10.71938562]\n",
      " [ -0.55633806]\n",
      " [  0.09490854]] \n",
      "\n",
      "\n",
      " bias : [0.17765572] \n",
      " bias_grad :[-19.36129688]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 41\n",
      "Starting forward propagation...\n",
      "Cost: 2749.431533291195\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.12524152 -1.46198739 -1.21600265]\n",
      " [-0.01687086 -0.33896516  0.18856099]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [0.79767676 0.11209457 0.32018283] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.12380354]\n",
      " [-0.71997313]\n",
      " [-0.7930966 ]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [0.3878959] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 42\n",
      "Starting forward propagation...\n",
      "Cost: 2738.3466367591304\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.15575941 -0.74459018 -0.16893952]\n",
      " [-0.84081568 -1.00891779  1.1104783 ]]\n",
      " weight_grad :[[ -2.72528036  -0.33900063   0.6844021 ]\n",
      " [  1.15408305   2.04345931 -33.21679069]] \n",
      "\n",
      "\n",
      " bias : [ 0.68271056  0.64409063 -0.73902783] \n",
      " bias_grad :[ -1.52219304   4.09478537 -22.75574791]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.48893942]\n",
      " [-0.6489917 ]\n",
      " [ 1.20299672]]\n",
      " weight_grad :[[ -4.87436923]\n",
      " [ -1.11314737]\n",
      " [-16.72031   ]] \n",
      "\n",
      "\n",
      " bias : [-0.51129963] \n",
      " bias_grad :[-22.02914009]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 43\n",
      "Starting forward propagation...\n",
      "Cost: 2749.0886169201817\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.84245435 -0.2305538   0.55331282]\n",
      " [ 0.36045055  1.42832007  0.51174551]]\n",
      " weight_grad :[[ 0.          1.22031921 -4.96946763]\n",
      " [ 0.         -0.86871734  4.39159828]] \n",
      "\n",
      "\n",
      " bias : [-0.7682805   0.67613137  0.28473146] \n",
      " bias_grad :[ 0.         -1.0358334   4.21558314]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.26517855]\n",
      " [ 0.29203356]\n",
      " [-1.73227321]]\n",
      " weight_grad :[[ 0.05173187]\n",
      " [-7.61047844]\n",
      " [-0.40112168]] \n",
      "\n",
      "\n",
      " bias : [-0.31301388] \n",
      " bias_grad :[-3.54696701]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 44\n",
      "Starting forward propagation...\n",
      "Cost: 2746.051207628765\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.26472197 -0.98204908  1.20314263]\n",
      " [ 0.09384389  0.80647016  0.50074121]]\n",
      " weight_grad :[[ 32.22244564   0.         -20.71762751]\n",
      " [  9.48837324   0.          -6.10061026]] \n",
      "\n",
      "\n",
      " bias : [ 0.96736868 -0.97733386 -0.74030576] \n",
      " bias_grad :[ 18.57028872   0.         -11.9398859 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.75532226]\n",
      " [-0.03681081]\n",
      " [ 1.12859567]]\n",
      " weight_grad :[[ -5.8819697 ]\n",
      " [  0.24007731]\n",
      " [-16.96083197]] \n",
      "\n",
      "\n",
      " bias : [-0.49466788] \n",
      " bias_grad :[-10.57941847]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 45\n",
      "Starting forward propagation...\n",
      "Cost: 2749.4399174155506\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.66114525  0.86434082 -1.36986311]\n",
      " [-0.33754264  0.0197817  -0.80401012]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [-0.91286782  0.49983002  0.58668803] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 1.45648185]\n",
      " [-0.34204002]\n",
      " [-0.19679617]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.74427604] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 46\n",
      "Starting forward propagation...\n",
      "Cost: 2695.6135037908007\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.14621681  1.42879882  1.07721732]\n",
      " [ 0.40197328  0.297123   -0.51450897]]\n",
      " weight_grad :[[-6.15534245e-02 -3.32539958e+01  6.67614385e-01]\n",
      " [ 1.42768555e+00 -1.11522103e+01  8.38214360e-03]] \n",
      "\n",
      "\n",
      " bias : [-0.42672579  0.67645319 -0.91182171] \n",
      " bias_grad :[  0.9889297  -31.78064691   0.46499927]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.50166128]\n",
      " [ 0.76303581]\n",
      " [-0.01901413]]\n",
      " weight_grad :[[  0.17953744]\n",
      " [-94.78581021]\n",
      " [-15.15839372]] \n",
      "\n",
      "\n",
      " bias : [-0.46214295] \n",
      " bias_grad :[-41.65026903]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 47\n",
      "Starting forward propagation...\n",
      "Cost: 2649.394136232685\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.48263475  0.01228853  1.77912132]\n",
      " [-0.2549433  -0.08761623 -0.25859256]]\n",
      " weight_grad :[[ -6.41150457 -26.28800315 -28.97993309]\n",
      " [  6.30917668  -0.50413886  -7.18955546]] \n",
      "\n",
      "\n",
      " bias : [-0.12962038  0.09807275  0.16615517] \n",
      " bias_grad :[  8.65406233 -33.04151528 -26.29827249]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.60669467]\n",
      " [ 0.8316707 ]\n",
      " [ 0.66806215]]\n",
      " weight_grad :[[-10.43641832]\n",
      " [ -4.22633696]\n",
      " [-80.72320984]] \n",
      "\n",
      "\n",
      " bias : [0.81323632] \n",
      " bias_grad :[-57.77817945]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 48\n",
      "Starting forward propagation...\n",
      "Cost: 2701.201522622048\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.31057473  0.22773045 -0.39601122]\n",
      " [-0.02282326  0.3826639  -0.83106102]]\n",
      " weight_grad :[[ 4.88837233 -2.4276366  -0.09246557]\n",
      " [-5.89854979 -2.31547649  0.74878461]] \n",
      "\n",
      "\n",
      " bias : [ 0.14697033  0.60757792 -0.46516473] \n",
      " bias_grad :[-9.28271876 -4.96865855 -0.666798  ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.35810461]\n",
      " [0.08176455]\n",
      " [0.09555333]]\n",
      " weight_grad :[[ -7.58838286]\n",
      " [-54.51893718]\n",
      " [ -2.2211665 ]] \n",
      "\n",
      "\n",
      " bias : [0.65252973] \n",
      " bias_grad :[-60.99433563]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 49\n",
      "Starting forward propagation...\n",
      "Cost: 2717.7397249847495\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.33226969  1.18986317  0.29392913]\n",
      " [-0.58470719 -0.39896796  1.19123695]]\n",
      " weight_grad :[[-20.24285657 -15.75440581  16.60416645]\n",
      " [  2.3291938    1.81274141   3.97609128]] \n",
      "\n",
      "\n",
      " bias : [0.37587979 0.37991487 0.27047473] \n",
      " bias_grad :[-16.48777294 -12.83193727  12.14408306]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.59329148]\n",
      " [ 0.4617409 ]\n",
      " [-0.66069772]]\n",
      " weight_grad :[[-58.19780369]\n",
      " [-52.72189817]\n",
      " [-19.46062367]] \n",
      "\n",
      "\n",
      " bias : [-0.53910764] \n",
      " bias_grad :[-27.79034144]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 50\n",
      "Starting forward propagation...\n",
      "Cost: 2749.062203419051\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.31787916 -0.2675798  -0.65017184]\n",
      " [ 0.84428986  0.35259407  0.88607536]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [0.26325411 0.38550413 0.52441202] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.08208588]\n",
      " [-0.07141131]\n",
      " [-0.48073855]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.24229516] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 51\n",
      "Starting forward propagation...\n",
      "Cost: 2668.9172611738277\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.94904107 -1.3534475   2.71720059]\n",
      " [ 0.74266422  0.02759599 -0.37373992]]\n",
      " weight_grad :[[-62.2181602   13.02347553   2.05808916]\n",
      " [-49.77509458 -13.76637465   0.75877673]] \n",
      "\n",
      "\n",
      " bias : [-0.10440687 -0.48744201 -0.91089261] \n",
      " bias_grad :[-69.44599379 -14.76619015   1.58490272]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 1.72832402]\n",
      " [ 0.95640889]\n",
      " [-0.05391614]]\n",
      " weight_grad :[[-51.29534748]\n",
      " [-10.61026615]\n",
      " [-71.05180672]] \n",
      "\n",
      "\n",
      " bias : [-0.31220312] \n",
      " bias_grad :[-50.971077]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 52\n",
      "Starting forward propagation...\n",
      "Cost: 2749.166242456791\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.91139461 -0.22520874  0.69190589]\n",
      " [ 0.65434455 -1.28656847  0.04860506]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [ 0.93505396  0.93740635 -0.10623255] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.04343011]\n",
      " [0.09235515]\n",
      " [0.3784577 ]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.99849559] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 53\n",
      "Starting forward propagation...\n",
      "Cost: 2681.8990601962014\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.89071048  0.19172609 -1.09190476]\n",
      " [-2.30259745  1.50245468 -0.65841476]]\n",
      " weight_grad :[[-2.66824153e-02 -2.81107168e+01 -2.76948683e+00]\n",
      " [ 4.62958642e+00 -6.58990751e+01  4.62476258e+00]] \n",
      "\n",
      "\n",
      " bias : [ 0.4066955  -0.92482182  0.93587276] \n",
      " bias_grad :[ -6.46824936 -56.23539817  19.89557137]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.53960867]\n",
      " [ 1.79264179]\n",
      " [-0.72283288]]\n",
      " weight_grad :[[-23.33297025]\n",
      " [-28.85732676]\n",
      " [-25.47563127]] \n",
      "\n",
      "\n",
      " bias : [0.36435001] \n",
      " bias_grad :[-55.46286969]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 54\n",
      "Starting forward propagation...\n",
      "Cost: 2748.2045281526052\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.16021608  0.07007093 -0.64609405]\n",
      " [-0.17331708 -0.93239885  0.68274835]]\n",
      " weight_grad :[[ 0.          1.36451182  3.47758538]\n",
      " [ 0.         -0.85068962  0.75080976]] \n",
      "\n",
      "\n",
      " bias : [-0.65357067 -0.51197187  0.81196923] \n",
      " bias_grad :[0.         1.10563831 2.30311535]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.0407867 ]\n",
      " [-0.19802845]\n",
      " [-0.73976033]]\n",
      " weight_grad :[[ 0.10592079]\n",
      " [-1.5920962 ]\n",
      " [-0.14268165]] \n",
      "\n",
      "\n",
      " bias : [0.10398715] \n",
      " bias_grad :[-12.54267604]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 55\n",
      "Starting forward propagation...\n",
      "Cost: 2549.672009485241\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.81927804 -0.20688539 -0.01464162]\n",
      " [ 0.84244581 -1.94153681  1.04137196]]\n",
      " weight_grad :[[-72.32472174  25.99290541   4.92636547]\n",
      " [-59.36532504  -3.23844196   7.04597546]] \n",
      "\n",
      "\n",
      " bias : [ 0.47275206  0.99463939 -0.15718518] \n",
      " bias_grad :[-83.88389008  23.92836719   6.85812523]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 2.09025042]\n",
      " [-1.70892406]\n",
      " [-0.22146679]]\n",
      " weight_grad :[[-105.84718805]\n",
      " [ -14.09101106]\n",
      " [ -27.88630758]] \n",
      "\n",
      "\n",
      " bias : [0.07743496] \n",
      " bias_grad :[-40.13102419]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 56\n",
      "Starting forward propagation...\n",
      "Cost: 2605.9686235748763\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.20599977 -0.09398644  1.36622864]\n",
      " [-2.02740773 -1.99775445  0.42956376]]\n",
      " weight_grad :[[ -7.35960775  -5.01285116 -70.9634283 ]\n",
      " [  6.12159592   5.45047748 -29.94270916]] \n",
      "\n",
      "\n",
      " bias : [-0.11716356  0.31413545 -0.19294657] \n",
      " bias_grad :[ -8.74558317  -8.72773462 -69.10890563]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.51483499]\n",
      " [0.45981741]\n",
      " [1.69264648]]\n",
      " weight_grad :[[-24.21671836]\n",
      " [-27.91976145]\n",
      " [-56.82413211]] \n",
      "\n",
      "\n",
      " bias : [0.30034017] \n",
      " bias_grad :[-59.74815751]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 57\n",
      "Starting forward propagation...\n",
      "Cost: 2738.5026428420883\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.65134618 -0.15452177  0.37844759]\n",
      " [-0.51341206  0.55670654  2.19214923]]\n",
      " weight_grad :[[-17.11754073   1.65264851   2.08139427]\n",
      " [  8.59875373  -0.51674923   0.58800951]] \n",
      "\n",
      "\n",
      " bias : [-0.24177654 -0.11598781 -0.47248394] \n",
      " bias_grad :[-15.15056309  -1.60959713   2.06977009]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.80340184]\n",
      " [ 0.63357167]\n",
      " [-0.35629051]]\n",
      " weight_grad :[[-14.7860614 ]\n",
      " [ -0.44807303]\n",
      " [ -2.80598947]] \n",
      "\n",
      "\n",
      " bias : [-0.03968363] \n",
      " bias_grad :[-21.39852709]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 58\n",
      "Starting forward propagation...\n",
      "Cost: 2746.873329154428\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.69518771 -0.64786555  1.98441698]\n",
      " [-1.09841231  0.64602237  0.82218199]]\n",
      " weight_grad :[[-1.11448874  2.6511526  -0.06663644]\n",
      " [ 1.45957579 -8.67956581  1.54670681]] \n",
      "\n",
      "\n",
      " bias : [ 0.44608383 -0.43408413 -0.79079865] \n",
      " bias_grad :[ 0.90121999 -5.57948302  1.07127076]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.01065319]\n",
      " [ 0.72643828]\n",
      " [-0.54269199]]\n",
      " weight_grad :[[-0.63889884]\n",
      " [-6.74911999]\n",
      " [-0.49826499]] \n",
      "\n",
      "\n",
      " bias : [-0.19554514] \n",
      " bias_grad :[-7.68060159]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 59\n",
      "Starting forward propagation...\n",
      "Cost: 2747.766887788177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.19026545  0.78288382 -0.15598594]\n",
      " [ 1.33826292 -0.12216204  0.86595128]]\n",
      " weight_grad :[[ -0.33265182   0.           2.39661766]\n",
      " [  1.79023899   0.         -12.89792557]] \n",
      "\n",
      "\n",
      " bias : [-0.00672812 -0.93266426  0.14512064] \n",
      " bias_grad :[ 1.07631354  0.         -7.75439029]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.11350866]\n",
      " [-0.08575353]\n",
      " [ 0.81778256]]\n",
      " weight_grad :[[-21.60065223]\n",
      " [  0.13064784]\n",
      " [-15.49083651]] \n",
      "\n",
      "\n",
      " bias : [-0.94350587] \n",
      " bias_grad :[-9.48221533]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 60\n",
      "Starting forward propagation...\n",
      "Cost: 2748.9885591645416\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.05168598  1.17170333  1.87569603]\n",
      " [ 0.57916969  1.55180007 -0.0787748 ]]\n",
      " weight_grad :[[ 0.47159216  0.69750848  0.        ]\n",
      " [-1.89658725 -2.80514777  0.        ]] \n",
      "\n",
      "\n",
      " bias : [-0.4406999   0.23352021 -0.00911055] \n",
      " bias_grad :[-1.18573008 -1.75375432  0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.1984582 ]\n",
      " [ 0.29352964]\n",
      " [-1.61455242]]\n",
      " weight_grad :[[ -2.7790236 ]\n",
      " [-13.44086589]\n",
      " [  0.05264431]] \n",
      "\n",
      "\n",
      " bias : [-0.58308092] \n",
      " bias_grad :[-5.97470937]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 61\n",
      "Starting forward propagation...\n",
      "Cost: 2742.3873780517465\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.47229812  0.5142392   0.00251045]\n",
      " [ 1.81868116 -0.96686217  1.8502136 ]]\n",
      " weight_grad :[[-0.41001424  2.10118096 -0.30963674]\n",
      " [ 0.67294414 -3.16361045  0.15593515]] \n",
      "\n",
      "\n",
      " bias : [ 0.12849836 -0.05133652 -0.5106978 ] \n",
      " bias_grad :[3.35125486 4.87473191 0.39521818]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.97961532]\n",
      " [-0.55608171]\n",
      " [-0.46956462]]\n",
      " weight_grad :[[-1.39870526]\n",
      " [-6.96715261]\n",
      " [-0.00807317]] \n",
      "\n",
      "\n",
      " bias : [0.83757313] \n",
      " bias_grad :[-14.69341212]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 62\n",
      "Starting forward propagation...\n",
      "Cost: 2640.7689559380665\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.70607297  0.59766112 -0.2247383 ]\n",
      " [-0.02937423 -1.49681042 -0.30271453]]\n",
      " weight_grad :[[ 11.1145462  -34.70042668   0.05615429]\n",
      " [-10.47546079   9.92804511   0.54407789]] \n",
      "\n",
      "\n",
      " bias : [-0.23249233  0.2610271   0.11432728] \n",
      " bias_grad :[-12.71741417 -33.86206081  -1.75206393]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.83681271]\n",
      " [1.2916647 ]\n",
      " [0.09351148]]\n",
      " weight_grad :[[ -5.06867257]\n",
      " [-33.95435868]\n",
      " [ -3.91227724]] \n",
      "\n",
      "\n",
      " bias : [0.94499485] \n",
      " bias_grad :[-59.65407798]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 63\n",
      "Starting forward propagation...\n",
      "Cost: 2740.8277655771167\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.15220856  1.34255811  1.01569711]\n",
      " [-0.3762627  -0.1257428   2.11954415]]\n",
      " weight_grad :[[ 0.          2.31151268 -0.40196208]\n",
      " [ 0.         -1.90180106  1.17227888]] \n",
      "\n",
      "\n",
      " bias : [-0.93190338 -0.59410776 -0.45001611] \n",
      " bias_grad :[0.         4.41860442 0.98907756]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.05665165]\n",
      " [-1.07571087]\n",
      " [-0.0522265 ]]\n",
      " weight_grad :[[  0.37064124]\n",
      " [ -0.29795234]\n",
      " [-31.05323333]] \n",
      "\n",
      "\n",
      " bias : [0.31881228] \n",
      " bias_grad :[-30.47791668]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 64\n",
      "Starting forward propagation...\n",
      "Cost: 2726.7270180199307\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.38597845 -0.02472194 -1.53092775]\n",
      " [-0.88608541  1.22163799  1.151722  ]]\n",
      " weight_grad :[[-0.56278472  7.84860605  1.83872826]\n",
      " [ 1.49869721  5.45384705  3.14597307]] \n",
      "\n",
      "\n",
      " bias : [-0.57722624 -0.73004221  0.18341943] \n",
      " bias_grad :[-1.08115122  6.04642638  5.80248665]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.20782101]\n",
      " [-0.8117243 ]\n",
      " [-1.14949041]]\n",
      " weight_grad :[[-1.99802061]\n",
      " [-2.21967276]\n",
      " [-1.10347115]] \n",
      "\n",
      "\n",
      " bias : [0.72459625] \n",
      " bias_grad :[-34.59032811]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 65\n",
      "Starting forward propagation...\n",
      "Cost: 2681.2377570378303\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.47474125 -0.16896177 -1.22254255]\n",
      " [-0.76258246 -0.13370949  0.12002384]]\n",
      " weight_grad :[[-13.86743945   0.          -3.73228692]\n",
      " [ -2.0820067    0.           6.23663392]] \n",
      "\n",
      "\n",
      " bias : [ 0.16153102 -0.49617451  0.74091154] \n",
      " bias_grad :[-12.4392495    0.           9.22833062]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.32395162]\n",
      " [-0.54148181]\n",
      " [-0.31025934]]\n",
      " weight_grad :[[-64.0958444 ]\n",
      " [  0.3884924 ]\n",
      " [-38.89771155]] \n",
      "\n",
      "\n",
      " bias : [0.9524209] \n",
      " bias_grad :[-60.89696008]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 66\n",
      "Starting forward propagation...\n",
      "Cost: 2720.292734875666\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.86254675 -1.90507235  0.94181282]\n",
      " [ 0.70991975  1.8898393   2.33868105]]\n",
      " weight_grad :[[-24.00428593   0.61498039   1.98815368]\n",
      " [ -8.36795012   2.12695051   1.13695203]] \n",
      "\n",
      "\n",
      " bias : [ 0.00669846 -0.8180267   0.38593374] \n",
      " bias_grad :[-21.28737733   1.51656754   1.82355806]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.56522234]\n",
      " [-0.37348967]\n",
      " [-0.05601212]]\n",
      " weight_grad :[[-47.35398687]\n",
      " [ -3.26108021]\n",
      " [-93.31153742]] \n",
      "\n",
      "\n",
      " bias : [0.18563105] \n",
      " bias_grad :[-43.78389014]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 67\n",
      "Starting forward propagation...\n",
      "Cost: 2748.9141749611176\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.82216302 -0.68247692 -1.19274595]\n",
      " [ 0.55966611  0.41134045 -0.02986216]]\n",
      " weight_grad :[[ 0.04515169 -0.42698676  0.        ]\n",
      " [-0.83080742 -0.94570658  0.        ]] \n",
      "\n",
      "\n",
      " bias : [ 0.84904594  0.12634693 -0.9625673 ] \n",
      " bias_grad :[0.78772249 1.22214099 0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.55221866]\n",
      " [-1.55719249]\n",
      " [-0.62205281]]\n",
      " weight_grad :[[-0.43452536]\n",
      " [-0.03019919]\n",
      " [ 0.01835242]] \n",
      "\n",
      "\n",
      " bias : [0.31500597] \n",
      " bias_grad :[-2.38162802]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 68\n",
      "Starting forward propagation...\n",
      "Cost: 2738.001765551551\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.951335    0.06872928 -0.09208095]\n",
      " [ 0.78279206 -0.91893246 -0.9933234 ]]\n",
      " weight_grad :[[ 2.59267591  0.51764204 -2.98897246]\n",
      " [-0.98387772 -0.67486514  5.32482647]] \n",
      "\n",
      "\n",
      " bias : [-0.1968564  -0.87820062  0.47085849] \n",
      " bias_grad :[ 2.53627502  0.51988891 -8.91016729]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.38200949]\n",
      " [-0.0775169 ]\n",
      " [ 0.45777459]]\n",
      " weight_grad :[[ -3.01655171]\n",
      " [ -2.33161096]\n",
      " [-20.0776899 ]] \n",
      "\n",
      "\n",
      " bias : [0.10429795] \n",
      " bias_grad :[-27.38337825]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 69\n",
      "Starting forward propagation...\n",
      "Cost: 2739.6176624698437\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-2.25582597 -0.56324819 -0.65979955]\n",
      " [-1.98503777 -0.03053401 -0.14522654]]\n",
      " weight_grad :[[ -1.50023208  -0.56202617  -0.20464326]\n",
      " [ 10.99179554 -15.63435404  -5.69273355]] \n",
      "\n",
      "\n",
      " bias : [0.84909172 0.66840293 0.65245015] \n",
      " bias_grad :[-10.35257041  16.20298637   5.89978223]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 1.5196151 ]\n",
      " [-2.69035399]\n",
      " [-0.97960353]]\n",
      " weight_grad :[[-17.91581877]\n",
      " [ -4.31962186]\n",
      " [ -4.91057275]] \n",
      "\n",
      "\n",
      " bias : [-0.29198742] \n",
      " bias_grad :[-6.81262671]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 70\n",
      "Starting forward propagation...\n",
      "Cost: 2740.222809549752\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.18928722  0.90961681  0.5139887 ]\n",
      " [ 0.66396773  1.5135827   0.91978975]]\n",
      " weight_grad :[[ 1.02737601  4.6024948   1.91603089]\n",
      " [-1.24925723 -0.62058336  0.40903704]] \n",
      "\n",
      "\n",
      " bias : [ 0.89721515  0.3893713  -0.57206843] \n",
      " bias_grad :[3.68946609 3.87146319 1.49197908]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.72865287]\n",
      " [-0.24950887]\n",
      " [-0.24849837]]\n",
      " weight_grad :[[ -1.57435479]\n",
      " [-18.99238431]\n",
      " [ -1.91403027]] \n",
      "\n",
      "\n",
      " bias : [0.69693844] \n",
      " bias_grad :[-21.82990865]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 71\n",
      "Starting forward propagation...\n",
      "Cost: 2745.032404872239\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.22423475  0.32711688  0.67681157]\n",
      " [ 1.47253574 -0.36995397 -1.80000878]]\n",
      " weight_grad :[[  2.49965242 -15.53148827   5.23988315]\n",
      " [  1.14936829  -3.45366662   0.36298282]] \n",
      "\n",
      "\n",
      " bias : [-0.9323945   0.37903029  0.27371207] \n",
      " bias_grad :[  1.69233015 -15.05520723   4.8083131 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.17100297]\n",
      " [ 0.58913881]\n",
      " [-0.256084  ]]\n",
      " weight_grad :[[ -3.81543288]\n",
      " [-16.1410074 ]\n",
      " [-16.41502707]] \n",
      "\n",
      "\n",
      " bias : [-0.03606769] \n",
      " bias_grad :[-25.55460114]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 72\n",
      "Starting forward propagation...\n",
      "Cost: 2706.4468906709626\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.27296607  1.06146087 -1.29597072]\n",
      " [ 2.65189113 -0.46976022 -1.76769471]]\n",
      " weight_grad :[[ -2.23717651  16.75799665  -1.98978197]\n",
      " [-10.6515037   14.68148008   0.39550149]] \n",
      "\n",
      "\n",
      " bias : [-0.8861138   0.29871405 -0.0685898 ] \n",
      " bias_grad :[-9.05495997 17.92680675  2.84208655]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.28660748]\n",
      " [-0.90065444]\n",
      " [-0.65462592]]\n",
      " weight_grad :[[-72.64055162]\n",
      " [-17.86896605]\n",
      " [ -1.76499896]] \n",
      "\n",
      "\n",
      " bias : [0.99711554] \n",
      " bias_grad :[-38.62665941]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 73\n",
      "Starting forward propagation...\n",
      "Cost: 2697.0540694289225\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.17492587  0.55493744 -1.16977288]\n",
      " [-0.28858152  0.13562713  0.94930049]]\n",
      " weight_grad :[[ 0.70240767 -6.76388059  1.81359857]\n",
      " [ 1.97227662 -1.55508721  8.43257344]] \n",
      "\n",
      "\n",
      " bias : [0.88269989 0.93324716 0.80519354] \n",
      " bias_grad :[-11.12889219  -8.51831256  16.31148767]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.58232163]\n",
      " [ 0.18147421]\n",
      " [-0.78615737]]\n",
      " weight_grad :[[-19.02299845]\n",
      " [-65.65193666]\n",
      " [-23.97177882]] \n",
      "\n",
      "\n",
      " bias : [0.99822939] \n",
      " bias_grad :[-46.93355901]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 74\n",
      "Starting forward propagation...\n",
      "Cost: 2749.3257352304313\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.80828901  1.86808115  0.05537666]\n",
      " [-0.16021953  0.13054852  0.54476269]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [-0.40563283 -0.85493878  0.19485254] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.04479309]\n",
      " [-0.16956158]\n",
      " [-0.84479337]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.41452152] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 75\n",
      "Starting forward propagation...\n",
      "Cost: 2748.648607565013\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.13123291 -0.8516261   1.18787089]\n",
      " [-0.3085534  -0.41292056  1.13741159]]\n",
      " weight_grad :[[-1.35292997  2.51028718  0.        ]\n",
      " [-0.66127056  0.47707013  0.        ]] \n",
      "\n",
      "\n",
      " bias : [-0.18332546  0.30246944  0.95178154] \n",
      " bias_grad :[ 1.19120129 -2.17737255  0.        ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.91397292]\n",
      " [ 0.797259  ]\n",
      " [-0.05871853]]\n",
      " weight_grad :[[-0.17775654]\n",
      " [-3.75462279]\n",
      " [ 0.01821415]] \n",
      "\n",
      "\n",
      " bias : [-0.83490714] \n",
      " bias_grad :[-2.73107303]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 76\n",
      "Starting forward propagation...\n",
      "Cost: 2722.054665330089\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.22955267 -0.36880763  0.1933432 ]\n",
      " [ 0.89078955  0.77492549  0.89309667]]\n",
      " weight_grad :[[4.15159467 1.88301213 7.89667008]\n",
      " [4.26813758 5.23718411 6.39393228]] \n",
      "\n",
      "\n",
      " bias : [-0.23642656  0.22663654 -0.91485026] \n",
      " bias_grad :[6.17583676 8.17627158 6.88365287]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.23942204]\n",
      " [-0.30756847]\n",
      " [-0.83139418]]\n",
      " weight_grad :[[-13.62351412]\n",
      " [-16.84096989]\n",
      " [ -0.79296717]] \n",
      "\n",
      "\n",
      " bias : [0.76561411] \n",
      " bias_grad :[-46.53012845]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 77\n",
      "Starting forward propagation...\n",
      "Cost: 2704.4367057323675\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 3.34975867  0.32793335 -0.33098271]\n",
      " [-0.236157   -0.08974542  1.23253433]]\n",
      " weight_grad :[[  6.94997448   7.04839863   0.02977736]\n",
      " [  2.94611545 -21.8790954   -0.09465912]] \n",
      "\n",
      "\n",
      " bias : [-0.76314532  0.91103928  0.42793155] \n",
      " bias_grad :[ 11.62650008 -32.68941649  -0.09767631]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.0829938 ]\n",
      " [ 0.94384787]\n",
      " [ 0.00341661]]\n",
      " weight_grad :[[-11.96564204]\n",
      " [-27.0238349 ]\n",
      " [-49.23269153]] \n",
      "\n",
      "\n",
      " bias : [0.90406681] \n",
      " bias_grad :[-34.63420078]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 78\n",
      "Starting forward propagation...\n",
      "Cost: 2682.876526311237\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.01363321  0.62696586 -0.63658094]\n",
      " [ 0.55341861 -0.4434258   0.64089105]]\n",
      " weight_grad :[[ -1.44370197  -3.45331574  10.24360929]\n",
      " [  4.99672845   0.748039   -21.62638577]] \n",
      "\n",
      "\n",
      " bias : [ 0.33484222 -0.59611084 -0.28849906] \n",
      " bias_grad :[  5.21446295  -2.39295745 -19.00065648]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.17103734]\n",
      " [ 0.13464645]\n",
      " [ 0.89053907]]\n",
      " weight_grad :[[-34.6418194 ]\n",
      " [ -7.56868645]\n",
      " [-16.37908452]] \n",
      "\n",
      "\n",
      " bias : [0.91492728] \n",
      " bias_grad :[-60.77367895]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 79\n",
      "Starting forward propagation...\n",
      "Cost: 2747.40085165629\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.20824344 -0.68504603  0.38435485]\n",
      " [-0.20059954  0.15160591  0.3819635 ]]\n",
      " weight_grad :[[ 2.06627389  3.12954082 -3.54081148]\n",
      " [ 0.85670455 -0.53268013  0.1286651 ]] \n",
      "\n",
      "\n",
      " bias : [0.48655705 0.48412814 0.86511207] \n",
      " bias_grad :[-3.17369553 -3.51480155  4.68522783]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.33431023]\n",
      " [ 0.34094845]\n",
      " [-0.42392066]]\n",
      " weight_grad :[[ -3.84413405]\n",
      " [-11.51304802]\n",
      " [ -6.4667243 ]] \n",
      "\n",
      "\n",
      " bias : [-0.08711021] \n",
      " bias_grad :[-11.19396156]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 80\n",
      "Starting forward propagation...\n",
      "Cost: 2658.2918222161843\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.29762317 -0.1501211   0.60699773]\n",
      " [-0.66052781 -0.62661719 -1.15239021]]\n",
      " weight_grad :[[-7.93934864 -8.15794228 -3.5990524 ]\n",
      " [-1.38327157 -3.19285384  2.33879037]] \n",
      "\n",
      "\n",
      " bias : [ 0.72287748  0.88393851 -0.58835223] \n",
      " bias_grad :[ -7.82762316 -16.25479564  -3.27238352]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.1887139 ]\n",
      " [0.33682859]\n",
      " [0.20768521]]\n",
      " weight_grad :[[-79.56461041]\n",
      " [-33.06191655]\n",
      " [-13.57977815]] \n",
      "\n",
      "\n",
      " bias : [0.99871206] \n",
      " bias_grad :[-60.24940997]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 81\n",
      "Starting forward propagation...\n",
      "Cost: 2747.3790862620995\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.30523384  2.43431642 -0.83253899]\n",
      " [ 1.26793187  0.79687716  0.08460592]]\n",
      " weight_grad :[[-0.89740022  0.          4.04092429]\n",
      " [ 0.62231409  0.          0.12606351]] \n",
      "\n",
      "\n",
      " bias : [-0.30476329  0.51074367 -0.1564391 ] \n",
      " bias_grad :[ 0.83337353  0.         -4.34157618]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.81543122]\n",
      " [-0.17767341]\n",
      " [ 0.68533936]]\n",
      " weight_grad :[[-0.27742527]\n",
      " [ 0.11264365]\n",
      " [-3.90225514]] \n",
      "\n",
      "\n",
      " bias : [-0.08403303] \n",
      " bias_grad :[-6.33492898]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 82\n",
      "Starting forward propagation...\n",
      "Cost: 2651.7936198567504\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.73352634 -1.77773334  0.08825507]\n",
      " [ 0.74945045 -0.97421416 -0.62135723]]\n",
      " weight_grad :[[ 11.16309264  18.49596059  -3.40588749]\n",
      " [-20.9194366  -10.3198056    3.4994462 ]] \n",
      "\n",
      "\n",
      " bias : [-0.14362595  0.07451087 -0.66027899] \n",
      " bias_grad :[-19.59292135 -27.20630332  -2.68513045]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.95620628]\n",
      " [2.03995351]\n",
      " [0.47887283]]\n",
      " weight_grad :[[-32.93452318]\n",
      " [-11.25805343]\n",
      " [ -0.91213926]] \n",
      "\n",
      "\n",
      " bias : [0.56600574] \n",
      " bias_grad :[-58.72001949]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 83\n",
      "Starting forward propagation...\n",
      "Cost: 2566.7506132536387\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.50669482 -0.20261297 -0.10766648]\n",
      " [ 2.50030265 -1.52683364  1.49228908]]\n",
      " weight_grad :[[-14.63270519  -0.87703617 -21.77247714]\n",
      " [-25.88414714   1.10686085 -63.3127812 ]] \n",
      "\n",
      "\n",
      " bias : [ 0.54804263  0.1077685  -0.27207856] \n",
      " bias_grad :[-31.26212222  -1.62476936 -61.20764779]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.67532476]\n",
      " [0.08421555]\n",
      " [1.6341514 ]]\n",
      " weight_grad :[[-131.98659444]\n",
      " [ -19.44401392]\n",
      " [ -45.92348008]] \n",
      "\n",
      "\n",
      " bias : [0.19443026] \n",
      " bias_grad :[-59.81448425]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 84\n",
      "Starting forward propagation...\n",
      "Cost: 2586.228094812347\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.11057407 -0.01186109 -0.90719008]\n",
      " [ 1.11071406  2.14802901  0.87741074]]\n",
      " weight_grad :[[-29.44178489 -22.18754066  -0.26213651]\n",
      " [-23.91387071 -47.25538642   8.84139064]] \n",
      "\n",
      "\n",
      " bias : [-0.66438912  0.59594524  0.45236891] \n",
      " bias_grad :[-30.75580899 -54.5597249    8.3259169 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.86053288]\n",
      " [ 1.20210611]\n",
      " [-0.26304039]]\n",
      " weight_grad :[[ -45.02291108]\n",
      " [-111.23199218]\n",
      " [ -44.58322972]] \n",
      "\n",
      "\n",
      " bias : [-0.02937175] \n",
      " bias_grad :[-49.31971062]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 85\n",
      "Starting forward propagation...\n",
      "Cost: 2736.1323162252975\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.53429937  0.7889504  -1.112443  ]\n",
      " [-0.54026335 -0.84755742 -1.73662953]]\n",
      " weight_grad :[[ 1.28935292e+01 -1.86321208e+01 -4.45896459e-03]\n",
      " [-4.21461562e-01  8.91207800e+00  2.87036281e+00]] \n",
      "\n",
      "\n",
      " bias : [ 0.8788638  -0.04323181 -0.84183056] \n",
      " bias_grad :[ 20.46956193 -15.43111027  -2.83886477]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.73423065]\n",
      " [ 0.89008348]\n",
      " [ 0.37408502]]\n",
      " weight_grad :[[-34.16176949]\n",
      " [-23.94912953]\n",
      " [ -6.20246807]] \n",
      "\n",
      "\n",
      " bias : [0.36697769] \n",
      " bias_grad :[-38.04128571]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 86\n",
      "Starting forward propagation...\n",
      "Cost: 2745.7708188066235\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.10224138 -1.15728252 -1.12703435]\n",
      " [ 0.690599   -2.331723   -1.25927564]]\n",
      " weight_grad :[[ 0.         -1.34410058 -0.06729935]\n",
      " [ 0.          4.91558455 -3.86188228]] \n",
      "\n",
      "\n",
      " bias : [-0.58256404  0.30844945 -0.86984098] \n",
      " bias_grad :[ 0.         -3.82396049  3.2318746 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[ 0.671696  ]\n",
      " [ 0.63345322]\n",
      " [-0.77476691]]\n",
      " weight_grad :[[  0.08658851]\n",
      " [-17.50054404]\n",
      " [ -2.74021412]] \n",
      "\n",
      "\n",
      " bias : [-0.92729821] \n",
      " bias_grad :[-6.03668966]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 87\n",
      "Starting forward propagation...\n",
      "Cost: 2749.180301599175\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.54690659 -1.32518807 -0.29003783]\n",
      " [ 2.07203613 -0.31555652  0.22938799]]\n",
      " weight_grad :[[-2.8969689   2.73674539  7.42722925]\n",
      " [ 2.80553872 -0.91761953 -3.646054  ]] \n",
      "\n",
      "\n",
      " bias : [-0.31076928 -0.77616773 -0.25239761] \n",
      " bias_grad :[ 2.14438187 -2.29344242 -6.04760419]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.47030185]\n",
      " [ 0.44101108]\n",
      " [ 1.37785602]]\n",
      " weight_grad :[[-0.37901109]\n",
      " [-3.5306268 ]\n",
      " [-1.06163978]] \n",
      "\n",
      "\n",
      " bias : [-0.24100909] \n",
      " bias_grad :[-5.20041909]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 88\n",
      "Starting forward propagation...\n",
      "Cost: 2731.385795475477\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.10423163 -0.82345573 -0.04592647]\n",
      " [ 0.32194363 -1.38168936 -0.3108161 ]]\n",
      " weight_grad :[[-0.8457786  -1.40755546  4.87408129]\n",
      " [ 0.74215552 13.63224562 -9.01879706]] \n",
      "\n",
      "\n",
      " bias : [-0.11688591 -0.12020527  0.01282584] \n",
      " bias_grad :[  1.82810214 -17.61423121  13.23171369]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.26357223]\n",
      " [ 1.59018278]\n",
      " [-0.91466871]]\n",
      " weight_grad :[[-3.19665742]\n",
      " [-9.17073815]\n",
      " [-2.92644071]] \n",
      "\n",
      "\n",
      " bias : [0.11821392] \n",
      " bias_grad :[-43.09414868]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 89\n",
      "Starting forward propagation...\n",
      "Cost: 2745.081319270727\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.17819939  1.26944886  0.91514787]\n",
      " [-0.02441661 -0.03806817 -0.77414046]]\n",
      " weight_grad :[[-1.02996184  0.         -0.05538106]\n",
      " [ 1.55469713  0.         -0.17620184]] \n",
      "\n",
      "\n",
      " bias : [ 0.75984238 -0.94493296 -0.50776661] \n",
      " bias_grad :[2.7444316  0.         0.13431945]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.48129703]\n",
      " [-0.25714385]\n",
      " [-0.25703166]]\n",
      " weight_grad :[[-1.68030005]\n",
      " [ 0.37023415]\n",
      " [ 0.27277684]] \n",
      "\n",
      "\n",
      " bias : [0.24910281] \n",
      " bias_grad :[-18.76417043]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 90\n",
      "Starting forward propagation...\n",
      "Cost: 2749.4411630550962\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.76180711  0.57165268  0.31406258]\n",
      " [-0.36773026 -1.45655559  0.32067396]]\n",
      " weight_grad :[[ 0.         -1.00295255 -1.78792137]\n",
      " [ 0.         -0.04890782  0.23895346]] \n",
      "\n",
      "\n",
      " bias : [-0.9264506   0.658821    0.33083368] \n",
      " bias_grad :[0.         0.89196052 1.79535679]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.20382182]\n",
      " [-1.18909177]\n",
      " [-1.9063307 ]]\n",
      " weight_grad :[[ 0.03565659]\n",
      " [-0.06950699]\n",
      " [-0.05655932]] \n",
      "\n",
      "\n",
      " bias : [0.30765595] \n",
      " bias_grad :[-1.96387295]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 91\n",
      "Starting forward propagation...\n",
      "Cost: 2741.6054468601624\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.48234333 -0.8135454  -0.58789901]\n",
      " [ 0.78637626 -0.47581229 -1.42341853]]\n",
      " weight_grad :[[ 1.99111799 -2.70712442 -0.41859104]\n",
      " [-4.32042268 -4.16240651  4.0609268 ]] \n",
      "\n",
      "\n",
      " bias : [ 0.53288399 -0.00263645  0.52896618] \n",
      " bias_grad :[ 7.77116965  5.9352928  -4.78197139]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-1.65936575]\n",
      " [-0.90742443]\n",
      " [ 0.43344341]]\n",
      " weight_grad :[[ -1.00643629]\n",
      " [ -4.58289497]\n",
      " [-18.6040674 ]] \n",
      "\n",
      "\n",
      " bias : [0.51411454] \n",
      " bias_grad :[-11.03251619]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 92\n",
      "Starting forward propagation...\n",
      "Cost: 2710.2709638825477\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-0.20447318 -1.99412643  2.05340714]\n",
      " [-1.78142951  0.82910717 -0.18582456]]\n",
      " weight_grad :[[ -2.85566205   6.021819   -22.62149376]\n",
      " [  3.59509992  -7.97252016  -4.98641509]] \n",
      "\n",
      "\n",
      " bias : [-0.92266399 -0.06328356  0.57093947] \n",
      " bias_grad :[ -2.95287909  -7.63135571 -19.21414648]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.39524418]\n",
      " [0.46509068]\n",
      " [0.51953258]]\n",
      " weight_grad :[[  -6.7808103 ]\n",
      " [ -38.17096557]\n",
      " [-108.52457009]] \n",
      "\n",
      "\n",
      " bias : [-0.73994383] \n",
      " bias_grad :[-52.14539826]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 93\n",
      "Starting forward propagation...\n",
      "Cost: 2735.755781759044\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.1307818   0.13539504 -2.25082526]\n",
      " [ 1.50379082  0.21547852  0.08547273]]\n",
      " weight_grad :[[ 5.02835878 -2.25758906 -0.32805792]\n",
      " [ 3.77234383  0.73519795  0.01632032]] \n",
      "\n",
      "\n",
      " bias : [-0.77099082  0.51143746  0.27310305] \n",
      " bias_grad :[ 6.42109311 -3.73465418  0.51606481]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.91728846]\n",
      " [ 0.10833713]\n",
      " [-0.05053689]]\n",
      " weight_grad :[[ -1.14783401]\n",
      " [-18.98969081]\n",
      " [-16.87323985]] \n",
      "\n",
      "\n",
      " bias : [0.37524099] \n",
      " bias_grad :[-34.49524427]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 94\n",
      "Starting forward propagation...\n",
      "Cost: 2713.7623422890583\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.4011802   0.67925705 -0.54427978]\n",
      " [-0.15368147  1.37643291  0.7973641 ]]\n",
      " weight_grad :[[  5.06118903 -17.19534939  12.0753332 ]\n",
      " [ -1.48375319 -13.50557279  14.72119784]] \n",
      "\n",
      "\n",
      " bias : [-0.54861884  0.47490949  0.7945652 ] \n",
      " bias_grad :[  3.18769011 -20.32824317  18.0148379 ]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.27947471]\n",
      " [ 0.46746476]\n",
      " [-0.47468462]]\n",
      " weight_grad :[[ -1.6598817 ]\n",
      " [-85.34407912]\n",
      " [-40.970308  ]] \n",
      "\n",
      "\n",
      " bias : [0.29611345] \n",
      " bias_grad :[-50.14361069]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 95\n",
      "Starting forward propagation...\n",
      "Cost: 2749.4513652245873\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 1.07461168  0.75728319 -1.79592771]\n",
      " [-1.0099743  -0.3332367   1.43100128]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [-0.01048215  0.40635391  0.49686841] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.66708889]\n",
      " [-0.15669887]\n",
      " [-0.71914746]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [0.23726812] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 96\n",
      "Starting forward propagation...\n",
      "Cost: 2666.737862491968\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.22882019  0.75636951 -0.19734678]\n",
      " [-2.1213012   0.48550324  0.58130904]]\n",
      " weight_grad :[[ -0.81798871 -11.57367759  -3.3249812 ]\n",
      " [  0.80139152  -7.46610738 -18.9273393 ]] \n",
      "\n",
      "\n",
      " bias : [-0.54787363 -0.13100096  0.01882033] \n",
      " bias_grad :[ -0.952489   -12.53870034 -19.09783813]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.06343308]\n",
      " [0.29372028]\n",
      " [0.48753309]]\n",
      " weight_grad :[[-20.45299709]\n",
      " [-36.46468597]\n",
      " [-21.85514085]] \n",
      "\n",
      "\n",
      " bias : [0.96649597] \n",
      " bias_grad :[-60.57066866]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 97\n",
      "Starting forward propagation...\n",
      "Cost: 2612.8763789680384\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.7677366   0.69297772 -0.04509247]\n",
      " [ 0.62226672  0.9642279   1.55888553]]\n",
      " weight_grad :[[ -2.52973117 -13.74345555 -24.44335502]\n",
      " [ -1.82653684 -23.56795995 -54.07365551]] \n",
      "\n",
      "\n",
      " bias : [-0.76276135 -0.22248178  0.88641234] \n",
      " bias_grad :[ -2.060174   -24.48654182 -62.09974403]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.08695463]\n",
      " [0.61408085]\n",
      " [1.36691716]]\n",
      " weight_grad :[[ -17.19835196]\n",
      " [ -43.61190446]\n",
      " [-101.13151834]] \n",
      "\n",
      "\n",
      " bias : [-0.72617658] \n",
      " bias_grad :[-45.43051032]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 98\n",
      "Starting forward propagation...\n",
      "Cost: 2720.079672534075\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[-1.93659712 -2.06515827 -0.32757814]\n",
      " [ 0.62070795 -0.33807521  1.40490988]]\n",
      " weight_grad :[[-0.5534951  13.7671854   0.22146549]\n",
      " [ 0.31352467 -5.25851714  7.1748707 ]] \n",
      "\n",
      "\n",
      " bias : [-0.5496619  -0.50853702  0.23514385] \n",
      " bias_grad :[  0.5420142  -14.88089523  14.54994739]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.06754769]\n",
      " [ 1.59161144]\n",
      " [-0.93949687]]\n",
      " weight_grad :[[-13.63488343]\n",
      " [-11.34203416]\n",
      " [-14.10931146]] \n",
      "\n",
      "\n",
      " bias : [0.69832437] \n",
      " bias_grad :[-33.19088424]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 99\n",
      "Starting forward propagation...\n",
      "Cost: 2749.4040983618215\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.13250336 -0.77485253 -0.20001645]\n",
      " [-0.00143477  0.14010374 -0.28616793]]\n",
      " weight_grad :[[0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "\n",
      " bias : [-0.37767037 -0.94193226  0.55601368] \n",
      " bias_grad :[0. 0. 0.]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[-0.38967197]\n",
      " [-1.47255619]\n",
      " [-0.74899296]]\n",
      " weight_grad :[[0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "\n",
      " bias : [-0.86173352] \n",
      " bias_grad :[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration 100\n",
      "Starting forward propagation...\n",
      "Cost: 2719.1374213813465\n",
      "Performing backward propagation...\n",
      "Calculating gradients...\n",
      "Layer: 1 \n",
      "\n",
      " weight : [[ 0.65335675 -0.93315157  1.42527469]\n",
      " [-0.23548164  0.71309896  1.62820386]]\n",
      " weight_grad :[[ -6.73398724   6.40812833 -10.68699739]\n",
      " [  0.3572325  -13.84311665 -13.52560929]] \n",
      "\n",
      "\n",
      " bias : [-0.9684793  -0.13714576 -0.24903389] \n",
      " bias_grad :[ -3.86991004 -11.75000899 -15.31832013]\n",
      "\n",
      "\n",
      "\n",
      "Layer: 2 \n",
      "\n",
      " weight : [[0.47886657]\n",
      " [0.57068363]\n",
      " [0.3818067 ]]\n",
      " weight_grad :[[ -1.14825317]\n",
      " [-24.6935077 ]\n",
      " [-87.52685246]] \n",
      "\n",
      "\n",
      " bias : [-0.41326653] \n",
      " bias_grad :[-44.88174378]\n",
      "\n",
      "\n",
      "\n",
      "2750.3863928416495\n",
      "2736.5055546128096\n",
      "2744.1648290500825\n",
      "2711.997768621748\n",
      "2744.9487985435767\n",
      "2694.4708542233075\n",
      "2745.6513337583183\n",
      "2630.6996004543416\n",
      "2708.1816841173927\n",
      "2728.916798761018\n",
      "2589.8669927999963\n",
      "2748.9928382161825\n",
      "2732.1156830675086\n",
      "2711.9398914744484\n",
      "2749.222694819594\n",
      "2751.815136416954\n",
      "2750.2045736017726\n",
      "2733.8877223368486\n",
      "2739.9244106129972\n",
      "2681.628892092658\n",
      "2745.5466484921194\n",
      "2674.6728573492414\n",
      "2748.7900294841534\n",
      "2674.8722075726955\n",
      "2712.952233878825\n",
      "2716.9413166232016\n",
      "2749.1310131222813\n",
      "2677.5439573331496\n",
      "2741.533592015224\n",
      "2660.5842719649245\n",
      "2734.9467072287134\n",
      "2750.3752792660916\n",
      "2704.382558787761\n",
      "2737.434111073201\n",
      "2660.384613165625\n",
      "2669.948073313313\n",
      "2686.010872221806\n",
      "2746.199461709941\n",
      "2749.9328900305936\n",
      "2744.35241589047\n",
      "2749.431533291195\n",
      "2738.3466367591304\n",
      "2749.0886169201817\n",
      "2746.051207628765\n",
      "2749.4399174155506\n",
      "2695.6135037908007\n",
      "2649.394136232685\n",
      "2701.201522622048\n",
      "2717.7397249847495\n",
      "2749.062203419051\n",
      "2668.9172611738277\n",
      "2749.166242456791\n",
      "2681.8990601962014\n",
      "2748.2045281526052\n",
      "2549.672009485241\n",
      "2605.9686235748763\n",
      "2738.5026428420883\n",
      "2746.873329154428\n",
      "2747.766887788177\n",
      "2748.9885591645416\n",
      "2742.3873780517465\n",
      "2640.7689559380665\n",
      "2740.8277655771167\n",
      "2726.7270180199307\n",
      "2681.2377570378303\n",
      "2720.292734875666\n",
      "2748.9141749611176\n",
      "2738.001765551551\n",
      "2739.6176624698437\n",
      "2740.222809549752\n",
      "2745.032404872239\n",
      "2706.4468906709626\n",
      "2697.0540694289225\n",
      "2749.3257352304313\n",
      "2748.648607565013\n",
      "2722.054665330089\n",
      "2704.4367057323675\n",
      "2682.876526311237\n",
      "2747.40085165629\n",
      "2658.2918222161843\n",
      "2747.3790862620995\n",
      "2651.7936198567504\n",
      "2566.7506132536387\n",
      "2586.228094812347\n",
      "2736.1323162252975\n",
      "2745.7708188066235\n",
      "2749.180301599175\n",
      "2731.385795475477\n",
      "2745.081319270727\n",
      "2749.4411630550962\n",
      "2741.6054468601624\n",
      "2710.2709638825477\n",
      "2735.755781759044\n",
      "2713.7623422890583\n",
      "2749.4513652245873\n",
      "2666.737862491968\n",
      "2612.8763789680384\n",
      "2720.079672534075\n",
      "2749.4040983618215\n",
      "2719.1374213813465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X = np.array([\n",
    "#     [0, 0, 0],\n",
    "#     [0, 0, 1],\n",
    "#     [0, 1, 0],\n",
    "#     [0, 1, 1],\n",
    "#     [1, 0, 0],\n",
    "#     [1, 0, 1],\n",
    "#     [1, 1, 0],\n",
    "#     [1, 1, 1]\n",
    "# ])\n",
    "\n",
    "# Y = np.sum(X, axis=1) % 2  \n",
    "\n",
    "X = np.random.rand(100, 2) * 10  # 100 samples, 2 features, values scaled to [0, 10]\n",
    "\n",
    "# Calculate target values\n",
    "Y = np.sum(X**2, axis=1).reshape(-1, 1)  # Sum of squares for each row\n",
    "\n",
    "# Normalize inputs\n",
    "X_mean=np.mean(X,axis=0)\n",
    "X_std=np.std(X,axis=0)\n",
    "standard_X = (X - X_mean)/X_std\n",
    "\n",
    "#hyperparameters\n",
    "train_iterations=100\n",
    "Layers=[3,1]\n",
    "\n",
    "\n",
    "# wt,bias,layers,cost_history=MLP(np.random.rand(10,3),[1,2,3,4,5,6,7,8,9,10],[4,2,1],100,0.01,0.5)\n",
    "wt, bias, layers, cost_history = MLP(standard_X, Y, Layers=Layers, iterations=train_iterations, learning_rate=0.05, error_margin=0.01)\n",
    "\n",
    "for i in cost_history:\n",
    "    print(i)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([i for i in range(train_iterations)],cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing Values using trained MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting forward propagation...\n",
      "Layer 1 Activation: [[-0.02038212  2.05942565 -0.019585  ]] \n",
      "\n",
      " Weights: [[ 0.99005612 -1.25355799  1.95962456]\n",
      " [-0.25334327  1.40525479  2.30448432]]\n",
      "\n",
      " Biases: [-0.7749838   0.45035469  0.51688212]\n",
      "\n",
      "\n",
      "Layer 2 Activation: [[5.44470449]] \n",
      "\n",
      " Weights: [[0.53627922]\n",
      " [1.80535902]\n",
      " [4.75814932]]\n",
      "\n",
      " Biases: [1.83082066]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[5.44470449]])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X=[1,5]\n",
    "X_std_test=(np.array(test_X)-X_mean)/X_std\n",
    "\n",
    "activation_values,W,B, inference,_=forward_propagation(X_std_test,Weights=wt,Biases=bias,Layers=Layers)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(activation_values)):\n",
    "    print(f\"Layer {i+1} Activation: {activation_values[i]} \\n\\n Weights: {W[i]}\\n\\n Biases: {B[i]}\\n\\n\")\n",
    "    \n",
    "\n",
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Evaluation\n",
    "\n",
    "Following aspects will be added in the future:\n",
    "1) Regularization to avoid overfitting\n",
    "2) Cross validation for overfitting training set\n",
    "3) Adam optimizer for momentum during learning\n",
    "4) Adapt Batch processing instead of using whole training set each iteration\n",
    "5) Class based approach for building model making the code easier and intuitive\n",
    "6) Option to use various activation functions besides ReLU\n",
    "7) Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.array([[1,2,3],[-1,0,10]])\n",
    "a=ReLU_derivative(b)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
